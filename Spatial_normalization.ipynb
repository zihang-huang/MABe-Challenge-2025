{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dbeb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ===== Paths (edit if needed) =====\n",
    "METADATA_CSV = Path(\"/kaggle/input/MABe-mouse-behavior-detection/train.csv\")\n",
    "TRACKING_ROOT = Path(\"/kaggle/input/MABe-mouse-behavior-detection/train_tracking\")\n",
    "\n",
    "path = Path(\"/kaggle/input/MABe-mouse-behavior-detection/train.csv\")\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "# set target folder + filename\n",
    "folder = Path(\"kaggle/working\")   # change to your desired folder\n",
    "filename = \"my_dataframe.csv\"\n",
    "\n",
    "# ensure folder exists\n",
    "folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# full path\n",
    "out_path = folder / filename\n",
    "\n",
    "# save\n",
    "df.to_csv(out_path, index=False)  # index=False is usually what you want\n",
    "\n",
    "print(f\"Saved to: {out_path.resolve()}\")\n",
    "\n",
    "# Output folder (keeps same lab subfolders)\n",
    "OUTPUT_ROOT = Path(\"kaggle/working/train_tracking_normalized\")\n",
    "\n",
    "# ===== Column names (with fallbacks) =====\n",
    "LAB_COL = \"lab_id\"\n",
    "VIDEO_COL = \"video_id\"\n",
    "\n",
    "# Primary expected name based on your description + earlier usage\n",
    "PPCM_COL_CANDIDATES = [\n",
    "    \"pix_per_cm_approx\",\n",
    "    \"pix_per_cm\",\n",
    "    \"pix per cm (approx)\",  # fallback if original naming survived to CSV\n",
    "]\n",
    "\n",
    "# Tracking coordinate columns\n",
    "X_COL = \"x\"\n",
    "Y_COL = \"y\"\n",
    "\n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f40e3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta = pd.read_csv(METADATA_CSV)\n",
    "\n",
    "# Resolve pix-per-cm column\n",
    "ppcm_col = None\n",
    "for c in PPCM_COL_CANDIDATES:\n",
    "    if c in df_meta.columns:\n",
    "        ppcm_col = c\n",
    "        break\n",
    "\n",
    "if ppcm_col is None:\n",
    "    raise KeyError(\n",
    "        f\"Could not find a pix-per-cm column. Tried: {PPCM_COL_CANDIDATES}\\n\"\n",
    "        f\"Available columns: {list(df_meta.columns)}\"\n",
    "    )\n",
    "\n",
    "# Ensure required columns exist\n",
    "missing = [c for c in [LAB_COL, VIDEO_COL, ppcm_col] if c not in df_meta.columns]\n",
    "if missing:\n",
    "    raise KeyError(f\"Missing required metadata columns: {missing}\")\n",
    "\n",
    "# Clean + normalize types\n",
    "df_meta = df_meta.copy()\n",
    "df_meta[LAB_COL] = df_meta[LAB_COL].astype(str)\n",
    "df_meta[VIDEO_COL] = df_meta[VIDEO_COL].astype(str)\n",
    "df_meta[ppcm_col] = pd.to_numeric(df_meta[ppcm_col], errors=\"coerce\")\n",
    "\n",
    "# Drop rows without pix_per_cm\n",
    "df_meta = df_meta.dropna(subset=[ppcm_col])\n",
    "\n",
    "# If the metadata has multiple rows per (lab_id, video_id),\n",
    "# keep the first non-null pix_per_cm (or you could aggregate).\n",
    "df_unique = (\n",
    "    df_meta[[LAB_COL, VIDEO_COL, ppcm_col]]\n",
    "    .drop_duplicates(subset=[LAB_COL, VIDEO_COL])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Build lookup dict: (lab_id, video_id) -> pix_per_cm\n",
    "ppcm_lookup = {\n",
    "    (row[LAB_COL], row[VIDEO_COL]): row[ppcm_col]\n",
    "    for _, row in df_unique.iterrows()\n",
    "}\n",
    "\n",
    "print(f\"Loaded metadata rows: {len(df_meta)}\")\n",
    "print(f\"Unique (lab_id, video_id) pairs with pix_per_cm: {len(df_unique)}\")\n",
    "print(f\"Using pix-per-cm column: {ppcm_col}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e4e2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_one_tracking_file(parquet_path: Path, pix_per_cm: float) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load a tracking parquet file, add normalized columns, and return the new DataFrame.\n",
    "    \"\"\"\n",
    "    df = pd.read_parquet(parquet_path)\n",
    "\n",
    "    # Basic column checks\n",
    "    if X_COL not in df.columns or Y_COL not in df.columns:\n",
    "        raise KeyError(\n",
    "            f\"Expected columns '{X_COL}' and '{Y_COL}' in {parquet_path.name}. \"\n",
    "            f\"Found: {list(df.columns)}\"\n",
    "        )\n",
    "\n",
    "    if pix_per_cm == 0 or pd.isna(pix_per_cm):\n",
    "        raise ValueError(f\"Invalid pix_per_cm={pix_per_cm} for {parquet_path}\")\n",
    "\n",
    "    df = df.copy()\n",
    "    df[\"x_normalized\"] = df[X_COL] / pix_per_cm\n",
    "    df[\"y_normalized\"] = df[Y_COL] / pix_per_cm\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e640dcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "processed = 0\n",
    "missing_files = 0\n",
    "missing_meta = 0\n",
    "errors = 0\n",
    "\n",
    "# Iterate over unique metadata pairs\n",
    "for (lab_id, video_id), pix_per_cm in ppcm_lookup.items():\n",
    "    in_path = TRACKING_ROOT / lab_id / f\"{video_id}.parquet\"\n",
    "    out_dir = OUTPUT_ROOT / lab_id\n",
    "    out_path = out_dir / f\"{video_id}.parquet\"\n",
    "\n",
    "    if not in_path.exists():\n",
    "        missing_files += 1\n",
    "        continue\n",
    "\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        df_norm = normalize_one_tracking_file(in_path, pix_per_cm)\n",
    "        df_norm.to_parquet(out_path, index=False)\n",
    "        processed += 1\n",
    "    except Exception as e:\n",
    "        errors += 1\n",
    "        print(f\"[ERROR] {lab_id=} {video_id=} file={in_path} -> {e}\")\n",
    "\n",
    "print(\"==== Spatial normalization summary ====\")\n",
    "print(f\"Processed files:     {processed}\")\n",
    "print(f\"Missing tracking:    {missing_files}\")\n",
    "print(f\"Metadata missing:    {missing_meta}\")  # kept for symmetry; not used in this loop\n",
    "print(f\"Errors:              {errors}\")\n",
    "print(f\"Output root:         {OUTPUT_ROOT.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb54ea0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
