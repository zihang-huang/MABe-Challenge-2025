{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal Convolutional Network (TCN) for MABe 2025\n",
    "\n",
    "This notebook implements a TCN for multi-agent behavior categorization using the preprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zihanghuang/data-mining/venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler, MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check for GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './data/processed/train'\n",
    "BATCH_SIZE = 64 \n",
    "SEQ_LEN = 100   # Window size for training\n",
    "HIDDEN_CHANNELS = 64\n",
    "KERNEL_SIZE = 3\n",
    "DROPOUT = 0.2\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Ensure data directory exists\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    raise FileNotFoundError(f\"Processed data directory not found: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MouseBehaviorDataset(Dataset):\n",
    "    def __init__(self, data_dir, video_ids, behavior_vocab=None, seq_len=100, is_training=True):\n",
    "        self.data_dir = data_dir\n",
    "        self.video_ids = video_ids\n",
    "        self.seq_len = seq_len\n",
    "        self.is_training = is_training\n",
    "        \n",
    "        # Load first video to get feature columns and behavior vocab if not provided\n",
    "        self.feature_cols = self._get_feature_columns()\n",
    "        if behavior_vocab is None:\n",
    "            self.behavior_vocab = self._build_vocab()\n",
    "        else:\n",
    "            self.behavior_vocab = behavior_vocab\n",
    "            \n",
    "        self.num_classes = len(self.behavior_vocab)\n",
    "        self.num_features = len(self.feature_cols)\n",
    "        \n",
    "        # Initialize scaler\n",
    "        self.scaler = self._get_scaler()\n",
    "        \n",
    "        print(f\"Dataset initialized with {len(video_ids)} videos\")\n",
    "        print(f\"Num features: {self.num_features}\")\n",
    "        print(f\"Num classes: {self.num_classes}\")\n",
    "\n",
    "    def _get_feature_columns(self):\n",
    "        # Load a sample file to check columns\n",
    "        sample_vid = self.video_ids[0]\n",
    "        df = pd.read_parquet(os.path.join(self.data_dir, f\"{sample_vid}.parquet\"))\n",
    "        \n",
    "        # Exclude non-feature columns\n",
    "        exclude = ['video_frame', 'mouse_id', 'video_id', 'lab_id']\n",
    "        cols = [c for c in df.columns if c not in exclude]\n",
    "        \n",
    "        # Handle variable dist_to_mouse columns by ensuring we have a fixed set for up to 4 mice\n",
    "        # We will dynamically add missing columns with 0s during loading\n",
    "        base_cols = [c for c in cols if not c.startswith('dist_to_mouse')]\n",
    "        for i in range(1, 5):\n",
    "            base_cols.append(f'dist_to_mouse_{i}')\n",
    "            \n",
    "        return base_cols\n",
    "\n",
    "    def _build_vocab(self):\n",
    "        behaviors = set()\n",
    "        # Scan a subset of annotations to build vocab (or all if feasible)\n",
    "        # For speed, we'll scan first 100 or all if less\n",
    "        scan_ids = self.video_ids[:100]\n",
    "        for vid in scan_ids:\n",
    "            anno_path = os.path.join(self.data_dir, f\"{vid}_annotations.parquet\")\n",
    "            if os.path.exists(anno_path):\n",
    "                df = pd.read_parquet(anno_path)\n",
    "                behaviors.update(df['action'].unique())\n",
    "        \n",
    "        return sorted(list(behaviors))\n",
    "\n",
    "    def _get_scaler(self):\n",
    "        import pickle\n",
    "        scaler_path = os.path.join(self.data_dir, 'scaler.pkl')\n",
    "        \n",
    "        if self.is_training:\n",
    "            print(\"Fitting scaler on training data subset...\")\n",
    "            scaler = StandardScaler()\n",
    "            # Fit on a random subset of 500 videos (or less if dataset is smaller)\n",
    "            sample_size = min(len(self.video_ids), 500)\n",
    "            sample_vids = np.random.choice(self.video_ids, sample_size, replace=False)\n",
    "            \n",
    "            all_feats = []\n",
    "            for vid in tqdm(sample_vids, desc=\"Loading scaler data\"):\n",
    "                feat_path = os.path.join(self.data_dir, f\"{vid}.parquet\")\n",
    "                if os.path.exists(feat_path):\n",
    "                    df = pd.read_parquet(feat_path)\n",
    "                    # Ensure columns\n",
    "                    for col in self.feature_cols:\n",
    "                        if col not in df.columns:\n",
    "                            df[col] = 0.0\n",
    "                    \n",
    "                    # Extract features\n",
    "                    feats = df[self.feature_cols].values.astype(np.float32)\n",
    "                    feats = np.nan_to_num(feats)\n",
    "                    \n",
    "                    # Subsample rows to save memory (e.g. every 10th frame)\n",
    "                    all_feats.append(feats[::10])\n",
    "            \n",
    "            if all_feats:\n",
    "                concat_feats = np.concatenate(all_feats, axis=0)\n",
    "                scaler.fit(concat_feats)\n",
    "                print(f\"Scaler fitted. Mean: {scaler.mean_[:5]}...\")\n",
    "                with open(scaler_path, 'wb') as f:\n",
    "                    pickle.dump(scaler, f)\n",
    "                return scaler\n",
    "            else:\n",
    "                print(\"Warning: No data found to fit scaler.\")\n",
    "                return None\n",
    "        else:\n",
    "            # Validation/Test: Load scaler\n",
    "            if os.path.exists(scaler_path):\n",
    "                print(f\"Loading scaler from {scaler_path}\")\n",
    "                with open(scaler_path, 'rb') as f:\n",
    "                    return pickle.load(f)\n",
    "            else:\n",
    "                print(\"Warning: Scaler not found for validation/test.\")\n",
    "                return None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        vid = self.video_ids[idx]\n",
    "        \n",
    "        # Load features\n",
    "        feat_path = os.path.join(self.data_dir, f\"{vid}.parquet\")\n",
    "        feat_df = pd.read_parquet(feat_path)\n",
    "        \n",
    "        # Normalize features (simple min-max or standardization would be better computed globally, \n",
    "        # but for now we do per-video or just raw if they are already roughly scaled)\n",
    "        # Given 'body_center' is in pixels, we should probably standardize.\n",
    "        # For simplicity in this baseline, we'll assume the model can handle it or add BatchNorm.\n",
    "        \n",
    "        # Ensure all feature columns exist\n",
    "        for col in self.feature_cols:\n",
    "            if col not in feat_df.columns:\n",
    "                feat_df[col] = 0.0\n",
    "        \n",
    "        # Extract feature matrix: (Num_Frames * Num_Mice, Num_Features)\n",
    "        # We need to structure it. TCN expects (Batch, Channels, Time).\n",
    "        # Here Batch will be (Video * Mouse). \n",
    "        # We will return list of mouse trajectories.\n",
    "        \n",
    "        mice_ids = feat_df['mouse_id'].unique()\n",
    "        mouse_features = []\n",
    "        mouse_labels = []\n",
    "        \n",
    "        # Load annotations\n",
    "        anno_path = os.path.join(self.data_dir, f\"{vid}_annotations.parquet\")\n",
    "        anno_df = pd.DataFrame()\n",
    "        if os.path.exists(anno_path):\n",
    "            anno_df = pd.read_parquet(anno_path)\n",
    "            \n",
    "        max_frame = feat_df['video_frame'].max()\n",
    "        \n",
    "        for mouse_id in mice_ids:\n",
    "            # Get mouse features\n",
    "            m_df = feat_df[feat_df['mouse_id'] == mouse_id].sort_values('video_frame')\n",
    "            # Reindex to ensure all frames are present\n",
    "            m_df = m_df.set_index('video_frame').reindex(range(int(max_frame) + 1), fill_value=0).reset_index()\n",
    "            \n",
    "            feats = m_df[self.feature_cols].values.astype(np.float32)\n",
    "            # Fill NaNs\n",
    "            feats = np.nan_to_num(feats)\n",
    "            \n",
    "            # Create labels\n",
    "            labels = np.zeros((len(feats), self.num_classes), dtype=np.float32)\n",
    "            \n",
    "            if not anno_df.empty:\n",
    "                mouse_annos = anno_df[anno_df['agent_id'] == mouse_id]\n",
    "                for _, row in mouse_annos.iterrows():\n",
    "                    action = row['action']\n",
    "                    if action in self.behavior_vocab:\n",
    "                        act_idx = self.behavior_vocab.index(action)\n",
    "                        start = int(row['start_frame'])\n",
    "                        stop = int(row['stop_frame'])\n",
    "                        # Clip to video duration\n",
    "                        start = max(0, start)\n",
    "                        stop = min(len(labels) - 1, stop)\n",
    "                        labels[start:stop+1, act_idx] = 1.0\n",
    "\n",
    "            # Random window sampling for training\n",
    "            if self.is_training and len(feats) > self.seq_len:\n",
    "                start_idx = np.random.randint(0, len(feats) - self.seq_len)\n",
    "                feats = feats[start_idx : start_idx + self.seq_len]\n",
    "                labels = labels[start_idx : start_idx + self.seq_len]\n",
    "            elif len(feats) < self.seq_len:\n",
    "                # Pad\n",
    "                pad_len = self.seq_len - len(feats)\n",
    "                feats = np.pad(feats, ((0, pad_len), (0, 0)))\n",
    "                labels = np.pad(labels, ((0, pad_len), (0, 0)))\n",
    "            \n",
    "            # Transpose features to (Channels, Time)\n",
    "            feats = feats.T\n",
    "            \n",
    "            mouse_features.append(feats)\n",
    "            mouse_labels.append(labels)\n",
    "            \n",
    "        # Stack mice (Num_Mice, Channels, Time)\n",
    "        # Note: Different videos have different num_mice. \n",
    "        # For batching, we usually flatten or pad mice dimension.\n",
    "        # Here we'll return the first mouse for simplicity of the baseline loop,\n",
    "        # or return a list and handle in collate_fn.\n",
    "        # Let's flatten: Dataset returns one sample per mouse per video?\n",
    "        # No, __getitem__ is per video. Let's return the first mouse as a sample for now\n",
    "        # to avoid complex collate functions in this demo.\n",
    "        # Ideally, we should iterate over (video, mouse) pairs.\n",
    "        \n",
    "        return mouse_features[0], mouse_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Wrapper for Mouse-Level Access\n",
    "To train properly, we want to iterate over all mice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MouseIndexDataset(Dataset):\n",
    "    \"\"\"Flattens (Video, Mouse) structure so each item is one mouse trajectory.\"\"\"\n",
    "    def __init__(self, data_dir, video_ids, behavior_vocab, seq_len=100, is_training=True):\n",
    "        self.base_dataset = MouseBehaviorDataset(data_dir, video_ids, behavior_vocab, seq_len, is_training)\n",
    "        self.indices = []\n",
    "        \n",
    "        # Pre-scan to build index (Video_Idx, Mouse_Idx)\n",
    "        print(\"Indexing mice...\")\n",
    "        for i, vid in enumerate(tqdm(video_ids)):\n",
    "            meta_path = os.path.join(data_dir, f\"{vid}_meta.json\")\n",
    "            try:\n",
    "                with open(meta_path, 'r') as f:\n",
    "                    meta = json.load(f)\n",
    "                num_mice = meta.get('num_mice', 2) # Default to 2 if missing\n",
    "                for m in range(num_mice):\n",
    "                    self.indices.append((i, m + 1)) # mouse_ids are 1-based\n",
    "            except:\n",
    "                pass # Skip if meta missing\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        vid_idx, mouse_id = self.indices[idx]\n",
    "        vid = self.base_dataset.video_ids[vid_idx]\n",
    "        \n",
    "        # Load features (Reusing code from Base, but targeted)\n",
    "        feat_path = os.path.join(self.base_dataset.data_dir, f\"{vid}.parquet\")\n",
    "        feat_df = pd.read_parquet(feat_path)\n",
    "        \n",
    "        for col in self.base_dataset.feature_cols:\n",
    "            if col not in feat_df.columns:\n",
    "                feat_df[col] = 0.0\n",
    "                \n",
    "        max_frame = feat_df['video_frame'].max()\n",
    "        m_df = feat_df[feat_df['mouse_id'] == mouse_id].sort_values('video_frame')\n",
    "        m_df = m_df.set_index('video_frame').reindex(range(int(max_frame) + 1), fill_value=0).reset_index()\n",
    "        \n",
    "        feats = m_df[self.base_dataset.feature_cols].values.astype(np.float32)\n",
    "        feats = np.nan_to_num(feats)\n",
    "        \n",
    "        # Normalize using base_dataset scaler\n",
    "        if hasattr(self.base_dataset, 'scaler') and self.base_dataset.scaler is not None:\n",
    "            feats = self.base_dataset.scaler.transform(feats)\n",
    "        \n",
    "        # Load labels\n",
    "        labels = np.zeros((len(feats), self.base_dataset.num_classes), dtype=np.float32)\n",
    "        anno_path = os.path.join(self.base_dataset.data_dir, f\"{vid}_annotations.parquet\")\n",
    "        if os.path.exists(anno_path):\n",
    "            anno_df = pd.read_parquet(anno_path)\n",
    "            mouse_annos = anno_df[anno_df['agent_id'] == mouse_id]\n",
    "            for _, row in mouse_annos.iterrows():\n",
    "                action = row['action']\n",
    "                if action in self.base_dataset.behavior_vocab:\n",
    "                    act_idx = self.base_dataset.behavior_vocab.index(action)\n",
    "                    start = max(0, int(row['start_frame']))\n",
    "                    stop = min(len(labels) - 1, int(row['stop_frame']))\n",
    "                    labels[start:stop+1, act_idx] = 1.0\n",
    "\n",
    "        # Windowing\n",
    "        if self.base_dataset.is_training and len(feats) > self.base_dataset.seq_len:\n",
    "            start_idx = np.random.randint(0, len(feats) - self.base_dataset.seq_len)\n",
    "            feats = feats[start_idx : start_idx + self.base_dataset.seq_len]\n",
    "            labels = labels[start_idx : start_idx + self.base_dataset.seq_len]\n",
    "        elif len(feats) < self.base_dataset.seq_len:\n",
    "            pad_len = self.base_dataset.seq_len - len(feats)\n",
    "            feats = np.pad(feats, ((0, pad_len), (0, 0)))\n",
    "            labels = np.pad(labels, ((0, pad_len), (0, 0)))\n",
    "            \n",
    "        return torch.tensor(feats.T), torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture (TCN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):\n",
    "        super(TemporalBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(n_inputs, n_outputs, kernel_size, stride=stride, padding=padding, dilation=dilation)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(n_outputs, n_outputs, kernel_size, stride=stride, padding=padding, dilation=dilation)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        \n",
    "        self.net = nn.Sequential(self.conv1, self.relu1, self.dropout1, \n",
    "                                 self.conv2, self.relu2, self.dropout2)\n",
    "        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "        # Trim output to match residual if padding caused mismatch (naive trimming)\n",
    "        if out.shape[2] != res.shape[2]:\n",
    "            out = out[:, :, :res.shape[2]]\n",
    "        return self.relu(out + res)\n",
    "\n",
    "class TCN(nn.Module):\n",
    "    def __init__(self, num_inputs, num_channels, kernel_size=3, dropout=0.2, num_classes=10):\n",
    "        super(TCN, self).__init__()\n",
    "        layers = []\n",
    "        num_levels = len(num_channels)\n",
    "        for i in range(num_levels):\n",
    "            dilation_size = 2 ** i\n",
    "            in_channels = num_inputs if i == 0 else num_channels[i-1]\n",
    "            out_channels = num_channels[i]\n",
    "            layers.append(TemporalBlock(in_channels, out_channels, kernel_size, stride=1, dilation=dilation_size,\n",
    "                                     padding=(kernel_size-1) * dilation_size, dropout=dropout))\n",
    "        \n",
    "        self.network = nn.Sequential(*layers)\n",
    "        self.classifier = nn.Conv1d(num_channels[-1], num_classes, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (Batch, Channels, Time)\n",
    "        y = self.network(x)\n",
    "        y = self.classifier(y)\n",
    "        # Output: (Batch, Classes, Time)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset initialized with 8114 videos\n",
      "Num features: 20\n",
      "Num classes: 5\n",
      "Dataset initialized with 6491 videos\n",
      "Num features: 20\n",
      "Num classes: 5\n",
      "Indexing mice...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6491/6491 [00:00<00:00, 28797.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset initialized with 1623 videos\n",
      "Num features: 20\n",
      "Num classes: 5\n",
      "Indexing mice...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1623/1623 [00:00<00:00, 29479.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for 10 epochs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 303/303 [01:16<00:00,  3.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 23.8246, Val Loss = 0.6639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 303/303 [01:23<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss = 0.3184, Val Loss = 0.3414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 303/303 [01:24<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss = 0.3694, Val Loss = 0.1715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 303/303 [01:23<00:00,  3.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss = 0.1130, Val Loss = 0.1308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 303/303 [01:24<00:00,  3.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss = 0.0933, Val Loss = 0.1318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 303/303 [01:24<00:00,  3.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss = 0.0680, Val Loss = 0.1059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 303/303 [01:24<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss = 0.0840, Val Loss = 0.0731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 303/303 [01:23<00:00,  3.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss = 0.0498, Val Loss = 0.0873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 303/303 [01:24<00:00,  3.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss = 0.0913, Val Loss = 0.0665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 303/303 [01:24<00:00,  3.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss = 0.0388, Val Loss = 0.0583\n",
      "Model saved to tcn_mouse_behavior.pth\n"
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "all_videos = [f.replace('.parquet', '') for f in os.listdir(DATA_DIR) \n",
    "              if f.endswith('.parquet') and not f.endswith('annotations.parquet')]\n",
    "\n",
    "train_vids, val_vids = train_test_split(all_videos, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create Datasets\n",
    "# First create base to get vocab\n",
    "base_ds = MouseBehaviorDataset(DATA_DIR, all_videos)\n",
    "vocab = base_ds.behavior_vocab\n",
    "num_features = base_ds.num_features\n",
    "\n",
    "train_ds = MouseIndexDataset(DATA_DIR, train_vids, vocab, seq_len=SEQ_LEN, is_training=True)\n",
    "val_ds = MouseIndexDataset(DATA_DIR, val_vids, vocab, seq_len=SEQ_LEN, is_training=False)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_ds, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "# Initialize Model\n",
    "channel_sizes = [HIDDEN_CHANNELS] * 4\n",
    "model = TCN(num_inputs=num_features, \n",
    "            num_channels=channel_sizes, \n",
    "            kernel_size=KERNEL_SIZE, \n",
    "            dropout=DROPOUT, \n",
    "            num_classes=len(vocab)).to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Training\n",
    "print(f\"Starting training for {EPOCHS} epochs...\")\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for features, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward\n",
    "        outputs = model(features)\n",
    "        \n",
    "        # Reshape for loss (Batch, Classes, Time) -> (Batch, Time, Classes) to match labels\n",
    "        outputs = outputs.permute(0, 2, 1)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    avg_train_loss = epoch_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for features, labels in val_loader:\n",
    "            features = features.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(features)\n",
    "            outputs = outputs.permute(0, 2, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}: Train Loss = {avg_train_loss:.4f}, Val Loss = {avg_val_loss:.4f}\")\n",
    "\n",
    "# Save model\n",
    "torch.save(model.state_dict(), 'tcn_mouse_behavior.pth')\n",
    "print(\"Model saved to tcn_mouse_behavior.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training History')\n",
    "plt.legend()\n",
    "plt.savefig('training_history.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-mining-venv",
   "language": "python",
   "name": "data-mining-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
